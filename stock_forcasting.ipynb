{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056ca774",
   "metadata": {},
   "source": [
    "# Có 5 loại cổ phiếu cần forcasting: 'ACB', 'BID', 'VCB', 'MBB', 'FPT' có trong 2 file csv là stock_data_2025_raw.csv và stock_data_2025_with_indicators.csv (có nhiều feature hơn)\n",
    "\n",
    "giờ trong mỗi file csv tôi muốn chia ra 5 nhóm cổ phiếu riêng để training mô hình forcasting theo time series với các window_size(3, 7, 14,30, 90)\n",
    "Trong giai đoạn training, mô hình được huấn luyện trên các đoạn dữ liệu (window) có độ dài cố định window_size.\n",
    "\n",
    "Mỗi đoạn (window) gồm window_size quan sát liên tiếp trong quá khứ, được dùng để dự đoán giá trị ở bước kế tiếp (+1 ngày).\n",
    "\n",
    "Trong giai đoạn forecasting (test), mô hình bắt đầu với window_size điểm dữ liệu cuối cùng của tập huấn luyện để dự đoán giá trị tiếp theo.\n",
    "Sau mỗi lần dự đoán, giá trị dự đoán mới được thêm vào cuối cửa sổ và loại bỏ điểm đầu tiên, tạo thành một “rolling window” mới để dự đoán bước kế tiếp.\n",
    "Quá trình này được lặp lại cho đến khi đạt số lượng bước dự báo mong muốn (multi-step recursive forecast).\n",
    "\n",
    "# Machine Learning Models for Time Series Forecasting\n",
    "ml_models = [\n",
    "    \"LinearRegression\",       # baseline tuyến tính, dễ giải thích\n",
    "    \"Ridge\",                  # regularized linear regression\n",
    "    \"Lasso\",                  # feature selection + regularization\n",
    "    \"ElasticNet\",             # mix giữa L1 và L2 regularization\n",
    "    \"DecisionTreeRegressor\",  # mô hình cây, dễ hiểu, non-linear\n",
    "    \"RandomForestRegressor\",  # ensemble mạnh mẽ, giảm overfit\n",
    "    \"ExtraTreesRegressor\",    # random forest cải tiến (faster)\n",
    "    \"GradientBoostingRegressor\", # boosting cổ điển\n",
    "    \"XGBRegressor\",           # XGBoost, mạnh và phổ biến\n",
    "    \"LGBMRegressor\",          # LightGBM, nhanh, xử lý large data tốt\n",
    "    \"CatBoostRegressor\",      # CatBoost, auto handling categorical\n",
    "    \"KNeighborsRegressor\",    # non-parametric, pattern-based\n",
    "    \"SVR\",                    # Support Vector Regression, robust\n",
    "    \"KernelRidge\",            # ridge với kernel, cho quan hệ phi tuyến\n",
    "    \"AdaBoostRegressor\",      # boosting đơn giản, dễ thử baseline\n",
    "    \"BaggingRegressor\"        # ensemble method, tăng độ ổn định\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning Models for Time Series Forecasting\n",
    "dl_models = [\n",
    "    \"MLP\",                    # Multi-Layer Perceptron (feed-forward baseline)\n",
    "    \"LSTM\",                   # Long Short-Term Memory — nhớ dài hạn, classic model\n",
    "    \"GRU\",                    # Gated Recurrent Unit — nhẹ hơn, nhanh hơn LSTM\n",
    "    \"BiLSTM\",                 # Bidirectional LSTM — nhìn cả quá khứ và “tương lai”\n",
    "    \"CNN1D\",                  # 1D Convolutional Neural Network — bắt local pattern\n",
    "    \"ConvLSTM\",               # CNN + LSTM — local pattern + temporal dependency\n",
    "    \"TCN\",                    # Temporal Convolutional Network — thay thế LSTM, song song hơn\n",
    "    \"Seq2Seq\",                # Encoder-Decoder (multi-step forecast)\n",
    "    \"AttentionLSTM\",          # LSTM kết hợp attention mechanism\n",
    "    \"Transformer\",            # base transformer (multi-head attention)\n",
    "    \"Informer\",               # efficient transformer cho long sequence\n",
    "    \"TFT\",                    # Temporal Fusion Transformer (interpretable)\n",
    "    \"DLinear\",                # linear transformer, cực nhanh & hiệu quả (2023+)\n",
    "    \"TimesNet\",               # SOTA 2024–2025, mô hình hóa pattern theo frequency\n",
    "    \"NBeats\",                 # Neural basis expansion — mạnh, interpretable\n",
    "    \"NHiTS\"                   # Improved NBeats — deep forecasting hiện đại\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d1064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Ready to load data.\n"
     ]
    }
   ],
   "source": [
    "# Imports and utilities\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# Ensure inline plotting in notebooks\n",
    "# %matplotlib inline  # VS Code usually sets this automatically\n",
    "plt.rcParams['figure.max_open_warning'] = 0\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "SYMBOLS = [\"ACB\", \"BID\", \"VCB\", \"MBB\", \"FPT\"]\n",
    "WINDOW_SIZES = [3, 7, 14, 30, 90]\n",
    "TEST_RATIO = 0.2  # last 20% as test by default\n",
    "SHOW_PLOTS = True  # display figures in notebook output cells\n",
    "\n",
    "# Metrics\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    return math.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = np.where(y_true == 0, np.nan, np.abs(y_true))\n",
    "    out = np.abs((y_true - y_pred) / denom) * 100.0\n",
    "    return np.nanmean(out)\n",
    "\n",
    "print(\"Setup complete. Ready to load data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91387043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time  open  high   low  close  volume symbol\n",
      "0 2015-01-05  2.35  2.34  2.31   2.34   55888    ACB\n",
      "1 2015-01-06  2.32  2.38  2.32   2.37   89802    ACB\n",
      "2 2015-01-07  2.37  2.44  2.36   2.40  232861    ACB\n",
      "3 2015-01-08  2.40  2.43  2.40   2.42   14880    ACB\n",
      "4 2015-01-09  2.42  2.48  2.37   2.43  693623    ACB\n",
      "        time  open  high   low  close    volume symbol  SMA_5  SMA_10  SMA_20  \\\n",
      "0 2015-01-05  2.35  2.34  2.31   2.34   55888.0    ACB  2.344   2.350  2.3550   \n",
      "1 2015-01-06  2.32  2.38  2.32   2.37   89802.0    ACB  2.348   2.352  2.3545   \n",
      "2 2015-01-07  2.37  2.44  2.36   2.40  232861.0    ACB  2.360   2.358  2.3555   \n",
      "3 2015-01-08  2.40  2.43  2.40   2.42   14880.0    ACB  2.376   2.363  2.3595   \n",
      "4 2015-01-09  2.42  2.48  2.37   2.43  693623.0    ACB  2.392   2.369  2.3635   \n",
      "\n",
      "   ...  Donchian_upper  Donchian_middle  Donchian_lower  Ulcer_Index  \\\n",
      "0  ...            2.41            2.360            2.31     1.157757   \n",
      "1  ...            2.41            2.360            2.31     1.152298   \n",
      "2  ...            2.44            2.375            2.31     1.101953   \n",
      "3  ...            2.44            2.375            2.31     1.006250   \n",
      "4  ...            2.48            2.395            2.31     0.948182   \n",
      "\n",
      "   Daily_Return  Price_Change  Price_Change_Pct  HL_Range  HL_Range_Pct  \\\n",
      "0     -0.425532         -0.01         -0.425532      0.03      1.298701   \n",
      "1      1.282051          0.05          2.155172      0.06      2.586207   \n",
      "2      1.265823          0.03          1.265823      0.08      3.389831   \n",
      "3      0.833333          0.02          0.833333      0.03      1.250000   \n",
      "4      0.413223          0.01          0.413223      0.11      4.641350   \n",
      "\n",
      "   Volume_Change_Pct  \n",
      "0          42.013518  \n",
      "1          60.682078  \n",
      "2         159.304915  \n",
      "3         -93.609922  \n",
      "4        4561.444892  \n",
      "\n",
      "[5 rows x 65 columns]\n",
      "{'raw_rows': 13381, 'ind_rows': 13381, 'symbols': ['ACB', 'BID', 'FPT', 'MBB', 'VCB']}\n"
     ]
    }
   ],
   "source": [
    "# Load CSVs\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# In notebooks, __file__ is not defined; use current working directory (VS Code defaults to notebook's folder)\n",
    "base_dir = Path.cwd()\n",
    "raw_csv = base_dir / \"stock_data_2025_raw.csv\"\n",
    "ind_csv = base_dir / \"stock_data_2025_with_indicators.csv\"\n",
    "\n",
    "assert raw_csv.exists(), f\"Missing file: {raw_csv}\"\n",
    "assert ind_csv.exists(), f\"Missing file: {ind_csv}\"\n",
    "\n",
    "raw = pd.read_csv(raw_csv)\n",
    "ind = pd.read_csv(ind_csv)\n",
    "\n",
    "# Normalize columns\n",
    "for df in (raw, ind):\n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "    df.sort_values(['symbol', 'time'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(raw.head())\n",
    "print(ind.head())\n",
    "print({\"raw_rows\": len(raw), \"ind_rows\": len(ind), \"symbols\": sorted(raw['symbol'].unique().tolist())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39bb9cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowing helpers ready.\n"
     ]
    }
   ],
   "source": [
    "# Prepare per-symbol datasets and sliding windows\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "\n",
    "\n",
    "def make_supervised(series: pd.Series, window: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Fill missing values to avoid NaNs in windows\n",
    "    s = series.astype(float).copy()\n",
    "    s = s.ffill().bfill()\n",
    "    vals = s.values\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(vals)):\n",
    "        window_vals = vals[i - window:i]\n",
    "        target_val = vals[i]\n",
    "        X.append(window_vals)\n",
    "        y.append(target_val)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_test_split_by_time(df: pd.DataFrame, test_ratio: float = TEST_RATIO) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    n = len(df)\n",
    "    n_test = max(1, int(n * test_ratio))\n",
    "    return df.iloc[: n - n_test], df.iloc[n - n_test :]\n",
    "\n",
    "\n",
    "def recursive_forecast(last_window: np.ndarray, steps: int, predict_next_fn) -> List[float]:\n",
    "    # last_window shape: (window,)\n",
    "    buf = np.array(last_window, dtype=float).copy()\n",
    "    preds = []\n",
    "    for _ in range(steps):\n",
    "        nxt = float(predict_next_fn(buf))\n",
    "        preds.append(nxt)\n",
    "        buf = np.roll(buf, -1)\n",
    "        buf[-1] = nxt\n",
    "    return preds\n",
    "\n",
    "print(\"Windowing helpers ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a2c74dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models wired: {'sklearn': True, 'hist_gbr': True, 'imputer': True}\n"
     ]
    }
   ],
   "source": [
    "# Baseline models: Naive (last value), SMA(k), optional LinearRegression / HistGradientBoostingRegressor\n",
    "try:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    SKLEARN_AVAILABLE = True\n",
    "    IMP_AVAILABLE = True\n",
    "except Exception:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    IMP_AVAILABLE = False\n",
    "\n",
    "# Optional: gradient boosting that handles NaNs\n",
    "if SKLEARN_AVAILABLE:\n",
    "    try:\n",
    "        from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "        HGB_AVAILABLE = True\n",
    "    except Exception:\n",
    "        HGB_AVAILABLE = False\n",
    "else:\n",
    "    HGB_AVAILABLE = False\n",
    "\n",
    "@dataclass\n",
    "class ModelSpec:\n",
    "    name: str\n",
    "    params: Dict\n",
    "\n",
    "\n",
    "def fit_naive(X: np.ndarray, y: np.ndarray):\n",
    "    # For naive, prediction is just last element of window, no fitting needed\n",
    "    return None\n",
    "\n",
    "\n",
    "def pred_naive(window_vec: np.ndarray) -> float:\n",
    "    return float(window_vec[-1])\n",
    "\n",
    "\n",
    "def fit_sma(X: np.ndarray, y: np.ndarray, k: int):\n",
    "    # For SMA, prediction is mean of last k items of window\n",
    "    return {\"k\": int(k)}\n",
    "\n",
    "\n",
    "def pred_sma(window_vec: np.ndarray, state: Dict) -> float:\n",
    "    k = int(state.get(\"k\", len(window_vec)))\n",
    "    k = max(1, min(k, len(window_vec)))\n",
    "    return float(np.mean(window_vec[-k:]))\n",
    "\n",
    "\n",
    "def fit_lr(X: np.ndarray, y: np.ndarray):\n",
    "    # Use an imputer so LR won't fail on any residual NaNs\n",
    "    if IMP_AVAILABLE:\n",
    "        model = make_pipeline(SimpleImputer(strategy=\"median\"), LinearRegression())\n",
    "    else:\n",
    "        model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def pred_lr(window_vec: np.ndarray, model) -> float:\n",
    "    return float(model.predict(window_vec.reshape(1, -1))[0])\n",
    "\n",
    "print(\"Models wired:\", {\"sklearn\": SKLEARN_AVAILABLE, \"hist_gbr\": HGB_AVAILABLE, \"imputer\": IMP_AVAILABLE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ccf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training/evaluation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>window</th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>HistGradientBoosting</td>\n",
       "      <td>test</td>\n",
       "      <td>3.426995</td>\n",
       "      <td>4.187213</td>\n",
       "      <td>15.783269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>test</td>\n",
       "      <td>0.181002</td>\n",
       "      <td>0.295322</td>\n",
       "      <td>0.889310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>Naive</td>\n",
       "      <td>test</td>\n",
       "      <td>0.180037</td>\n",
       "      <td>0.294681</td>\n",
       "      <td>0.884878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>SMA3</td>\n",
       "      <td>test</td>\n",
       "      <td>0.236461</td>\n",
       "      <td>0.372942</td>\n",
       "      <td>1.158833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>SMA5</td>\n",
       "      <td>test</td>\n",
       "      <td>0.236461</td>\n",
       "      <td>0.372942</td>\n",
       "      <td>1.158833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACB</td>\n",
       "      <td>7</td>\n",
       "      <td>HistGradientBoosting</td>\n",
       "      <td>test</td>\n",
       "      <td>3.390145</td>\n",
       "      <td>4.147768</td>\n",
       "      <td>15.606009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACB</td>\n",
       "      <td>7</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>test</td>\n",
       "      <td>0.182998</td>\n",
       "      <td>0.297325</td>\n",
       "      <td>0.898135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACB</td>\n",
       "      <td>7</td>\n",
       "      <td>Naive</td>\n",
       "      <td>test</td>\n",
       "      <td>0.179981</td>\n",
       "      <td>0.294817</td>\n",
       "      <td>0.884086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACB</td>\n",
       "      <td>7</td>\n",
       "      <td>SMA3</td>\n",
       "      <td>test</td>\n",
       "      <td>0.236179</td>\n",
       "      <td>0.372916</td>\n",
       "      <td>1.156493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACB</td>\n",
       "      <td>7</td>\n",
       "      <td>SMA5</td>\n",
       "      <td>test</td>\n",
       "      <td>0.278274</td>\n",
       "      <td>0.435771</td>\n",
       "      <td>1.366626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol  window                 model split       mae      rmse       mape\n",
       "0    ACB       3  HistGradientBoosting  test  3.426995  4.187213  15.783269\n",
       "1    ACB       3      LinearRegression  test  0.181002  0.295322   0.889310\n",
       "2    ACB       3                 Naive  test  0.180037  0.294681   0.884878\n",
       "3    ACB       3                  SMA3  test  0.236461  0.372942   1.158833\n",
       "4    ACB       3                  SMA5  test  0.236461  0.372942   1.158833\n",
       "5    ACB       7  HistGradientBoosting  test  3.390145  4.147768  15.606009\n",
       "6    ACB       7      LinearRegression  test  0.182998  0.297325   0.898135\n",
       "7    ACB       7                 Naive  test  0.179981  0.294817   0.884086\n",
       "8    ACB       7                  SMA3  test  0.236179  0.372916   1.156493\n",
       "9    ACB       7                  SMA5  test  0.278274  0.435771   1.366626"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training + forecasting loop with NaN-safe handling and in-cell plots\n",
    "results = []\n",
    "plots_dir = base_dir / \"charts\"\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "max_plots_per_symbol = 4  # avoid overly long output; adjust as needed\n",
    "\n",
    "for symbol in SYMBOLS:\n",
    "    df_sym_raw = raw[raw.symbol == symbol].copy()\n",
    "    df_sym_ind = ind[ind.symbol == symbol].copy()\n",
    "\n",
    "    # choose target and date source consistently\n",
    "    if len(df_sym_ind):\n",
    "        target_df = df_sym_ind\n",
    "    else:\n",
    "        target_df = df_sym_raw\n",
    "\n",
    "    target_series = target_df['close'].astype(float).copy()\n",
    "    date_series = target_df['time'].reset_index(drop=True) if 'time' in target_df.columns else pd.Series(range(len(target_series)))\n",
    "\n",
    "    # Fill missing target values for supervised framing; keep a note\n",
    "    target_series = target_series.ffill().bfill()\n",
    "\n",
    "    plotted_count = 0\n",
    "    for window in WINDOW_SIZES:\n",
    "        if len(target_series) <= window + 5:\n",
    "            continue  # not enough data\n",
    "\n",
    "        X_all, y_all = make_supervised(target_series, window)\n",
    "        dates = date_series[window:].reset_index(drop=True)\n",
    "\n",
    "        # Drop any rows that still contain NaNs (defensive)\n",
    "        mask = np.isfinite(X_all).all(axis=1) & np.isfinite(y_all)\n",
    "        X_all = X_all[mask]\n",
    "        y_all = y_all[mask]\n",
    "        dates = dates[mask]\n",
    "        if len(y_all) < 10:\n",
    "            continue\n",
    "\n",
    "        # time split\n",
    "        n = len(y_all)\n",
    "        n_test = max(5, int(n * TEST_RATIO))\n",
    "        X_train, y_train = X_all[:-n_test], y_all[:-n_test]\n",
    "        X_test, y_test = X_all[-n_test:], y_all[-n_test:]\n",
    "        dates_test = dates[-n_test:]\n",
    "\n",
    "        # Define model list per window\n",
    "        model_specs: List[ModelSpec] = [\n",
    "            ModelSpec(\"Naive\", {}),\n",
    "            ModelSpec(\"SMA3\", {\"k\": min(3, window)}),\n",
    "            ModelSpec(\"SMA5\", {\"k\": min(5, window)}),\n",
    "        ]\n",
    "        if SKLEARN_AVAILABLE:\n",
    "            model_specs.append(ModelSpec(\"LinearRegression\", {}))\n",
    "        if 'HGB_AVAILABLE' in globals() and HGB_AVAILABLE:\n",
    "            model_specs.append(ModelSpec(\"HistGradientBoosting\", {}))\n",
    "\n",
    "        for spec in model_specs:\n",
    "            if spec.name == \"Naive\":\n",
    "                model = fit_naive(X_train, y_train)\n",
    "                predict_next = lambda w: pred_naive(w)\n",
    "            elif spec.name.startswith(\"SMA\"):\n",
    "                model = fit_sma(X_train, y_train, k=spec.params.get(\"k\", window))\n",
    "                predict_next = lambda w, m=model: pred_sma(w, m)\n",
    "            elif spec.name == \"LinearRegression\" and SKLEARN_AVAILABLE:\n",
    "                # LR requires finite values only (already ensured), train\n",
    "                model = fit_lr(X_train, y_train)\n",
    "                predict_next = lambda w, m=model: pred_lr(w, m)\n",
    "            elif spec.name == \"HistGradientBoosting\" and HGB_AVAILABLE:\n",
    "                model = HistGradientBoostingRegressor(random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "                predict_next = lambda w, m=model: float(m.predict(w.reshape(1, -1))[0])\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # One-step predictions on test windows (standard evaluation)\n",
    "            y_pred_1 = np.array([predict_next(w) for w in X_test])\n",
    "            res = {\n",
    "                \"symbol\": symbol,\n",
    "                \"window\": window,\n",
    "                \"model\": spec.name,\n",
    "                \"split\": \"test\",\n",
    "                \"mae\": mae(y_test, y_pred_1),\n",
    "                \"rmse\": rmse(y_test, y_pred_1),\n",
    "                \"mape\": mape(y_test, y_pred_1),\n",
    "            }\n",
    "            results.append(res)\n",
    "\n",
    "            # Multi-step recursive forecast over the same horizon (start from last train window)\n",
    "            last_window = X_all[-n_test - 1]\n",
    "            y_pred_multi = recursive_forecast(last_window, steps=n_test, predict_next_fn=predict_next)\n",
    "\n",
    "            # Plot inside the cell and also save to disk\n",
    "            fig, ax = plt.subplots(figsize=(9, 4))\n",
    "            ax.plot(dates_test, y_test, label=\"Actual\", color=\"#1f77b4\")\n",
    "            ax.plot(dates_test, y_pred_1, label=\"1-step\", color=\"#ff7f0e\")\n",
    "            ax.plot(dates_test, y_pred_multi, label=\"Recursive\", color=\"#2ca02c\", linestyle=\"--\")\n",
    "            ax.set_title(f\"{symbol} window={window} model={spec.name}\")\n",
    "            ax.set_xlabel(\"Date\")\n",
    "            ax.set_ylabel(\"Close\")\n",
    "            ax.legend(loc=\"best\")\n",
    "            fig.tight_layout()\n",
    "\n",
    "            # Show inline\n",
    "            if SHOW_PLOTS and plotted_count < max_plots_per_symbol:\n",
    "                display(fig)\n",
    "                plotted_count += 1\n",
    "            \n",
    "            # Save file\n",
    "            plot_path = plots_dir / f\"{symbol}_w{window}_{spec.name}.png\"\n",
    "            fig.savefig(plot_path, dpi=120)\n",
    "            plt.close(fig)\n",
    "\n",
    "print(\"Finished training/evaluation.\")\n",
    "res_df = pd.DataFrame(results).sort_values([\"symbol\", \"window\", \"model\"]).reset_index(drop=True)\n",
    "res_csv = plots_dir / \"baseline_results.csv\"\n",
    "res_df.to_csv(res_csv, index=False)\n",
    "res_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f8af7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>window</th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>HistGradientBoosting</td>\n",
       "      <td>test</td>\n",
       "      <td>3.426995</td>\n",
       "      <td>4.187213</td>\n",
       "      <td>15.783269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>test</td>\n",
       "      <td>0.181002</td>\n",
       "      <td>0.295322</td>\n",
       "      <td>0.889310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>Naive</td>\n",
       "      <td>test</td>\n",
       "      <td>0.180037</td>\n",
       "      <td>0.294681</td>\n",
       "      <td>0.884878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>SMA3</td>\n",
       "      <td>test</td>\n",
       "      <td>0.236461</td>\n",
       "      <td>0.372942</td>\n",
       "      <td>1.158833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>SMA5</td>\n",
       "      <td>test</td>\n",
       "      <td>0.236461</td>\n",
       "      <td>0.372942</td>\n",
       "      <td>1.158833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MBB</td>\n",
       "      <td>90</td>\n",
       "      <td>HistGradientBoosting</td>\n",
       "      <td>test</td>\n",
       "      <td>2.243083</td>\n",
       "      <td>3.874158</td>\n",
       "      <td>11.012027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>MBB</td>\n",
       "      <td>90</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>test</td>\n",
       "      <td>0.195119</td>\n",
       "      <td>0.302295</td>\n",
       "      <td>1.156099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>MBB</td>\n",
       "      <td>90</td>\n",
       "      <td>Naive</td>\n",
       "      <td>test</td>\n",
       "      <td>0.188298</td>\n",
       "      <td>0.295531</td>\n",
       "      <td>1.109522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MBB</td>\n",
       "      <td>90</td>\n",
       "      <td>SMA3</td>\n",
       "      <td>test</td>\n",
       "      <td>0.244726</td>\n",
       "      <td>0.396925</td>\n",
       "      <td>1.434116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>MBB</td>\n",
       "      <td>90</td>\n",
       "      <td>SMA5</td>\n",
       "      <td>test</td>\n",
       "      <td>0.295056</td>\n",
       "      <td>0.480210</td>\n",
       "      <td>1.723052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  window                 model split       mae      rmse       mape\n",
       "0     ACB       3  HistGradientBoosting  test  3.426995  4.187213  15.783269\n",
       "1     ACB       3      LinearRegression  test  0.181002  0.295322   0.889310\n",
       "2     ACB       3                 Naive  test  0.180037  0.294681   0.884878\n",
       "3     ACB       3                  SMA3  test  0.236461  0.372942   1.158833\n",
       "4     ACB       3                  SMA5  test  0.236461  0.372942   1.158833\n",
       "..    ...     ...                   ...   ...       ...       ...        ...\n",
       "95    MBB      90  HistGradientBoosting  test  2.243083  3.874158  11.012027\n",
       "96    MBB      90      LinearRegression  test  0.195119  0.302295   1.156099\n",
       "97    MBB      90                 Naive  test  0.188298  0.295531   1.109522\n",
       "98    MBB      90                  SMA3  test  0.244726  0.396925   1.434116\n",
       "99    MBB      90                  SMA5  test  0.295056  0.480210   1.723052\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ee66e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>window</th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACB</td>\n",
       "      <td>3</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.180037</td>\n",
       "      <td>0.294681</td>\n",
       "      <td>0.884878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACB</td>\n",
       "      <td>7</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.179981</td>\n",
       "      <td>0.294817</td>\n",
       "      <td>0.884086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACB</td>\n",
       "      <td>14</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.180452</td>\n",
       "      <td>0.295333</td>\n",
       "      <td>0.886136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACB</td>\n",
       "      <td>30</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.180890</td>\n",
       "      <td>0.296043</td>\n",
       "      <td>0.887499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACB</td>\n",
       "      <td>90</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.181725</td>\n",
       "      <td>0.297869</td>\n",
       "      <td>0.886485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BID</td>\n",
       "      <td>3</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.415063</td>\n",
       "      <td>0.595035</td>\n",
       "      <td>1.106202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BID</td>\n",
       "      <td>7</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.415749</td>\n",
       "      <td>0.595012</td>\n",
       "      <td>1.108420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BID</td>\n",
       "      <td>14</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.414737</td>\n",
       "      <td>0.593709</td>\n",
       "      <td>1.104955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BID</td>\n",
       "      <td>30</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.414367</td>\n",
       "      <td>0.594219</td>\n",
       "      <td>1.103302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BID</td>\n",
       "      <td>90</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.412766</td>\n",
       "      <td>0.590717</td>\n",
       "      <td>1.094849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FPT</td>\n",
       "      <td>3</td>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>1.187237</td>\n",
       "      <td>1.680814</td>\n",
       "      <td>1.215549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FPT</td>\n",
       "      <td>7</td>\n",
       "      <td>Naive</td>\n",
       "      <td>1.192809</td>\n",
       "      <td>1.685614</td>\n",
       "      <td>1.219468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FPT</td>\n",
       "      <td>14</td>\n",
       "      <td>Naive</td>\n",
       "      <td>1.195771</td>\n",
       "      <td>1.688525</td>\n",
       "      <td>1.221517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FPT</td>\n",
       "      <td>30</td>\n",
       "      <td>Naive</td>\n",
       "      <td>1.198261</td>\n",
       "      <td>1.692248</td>\n",
       "      <td>1.221464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FPT</td>\n",
       "      <td>90</td>\n",
       "      <td>Naive</td>\n",
       "      <td>1.205338</td>\n",
       "      <td>1.698462</td>\n",
       "      <td>1.219182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MBB</td>\n",
       "      <td>3</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.185861</td>\n",
       "      <td>0.292407</td>\n",
       "      <td>1.104328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MBB</td>\n",
       "      <td>7</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.185861</td>\n",
       "      <td>0.292407</td>\n",
       "      <td>1.104328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MBB</td>\n",
       "      <td>14</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.186259</td>\n",
       "      <td>0.292874</td>\n",
       "      <td>1.105988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MBB</td>\n",
       "      <td>30</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.187202</td>\n",
       "      <td>0.293697</td>\n",
       "      <td>1.111324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MBB</td>\n",
       "      <td>90</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.188298</td>\n",
       "      <td>0.295531</td>\n",
       "      <td>1.109522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VCB</td>\n",
       "      <td>3</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.491854</td>\n",
       "      <td>0.761055</td>\n",
       "      <td>0.818923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VCB</td>\n",
       "      <td>7</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.491854</td>\n",
       "      <td>0.761055</td>\n",
       "      <td>0.818923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VCB</td>\n",
       "      <td>14</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.489211</td>\n",
       "      <td>0.758946</td>\n",
       "      <td>0.814442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>VCB</td>\n",
       "      <td>30</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.489735</td>\n",
       "      <td>0.759966</td>\n",
       "      <td>0.815256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VCB</td>\n",
       "      <td>90</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.488859</td>\n",
       "      <td>0.762184</td>\n",
       "      <td>0.813183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  window             model       mae      rmse      mape\n",
       "0     ACB       3             Naive  0.180037  0.294681  0.884878\n",
       "1     ACB       7             Naive  0.179981  0.294817  0.884086\n",
       "2     ACB      14             Naive  0.180452  0.295333  0.886136\n",
       "3     ACB      30             Naive  0.180890  0.296043  0.887499\n",
       "4     ACB      90             Naive  0.181725  0.297869  0.886485\n",
       "5     BID       3  LinearRegression  0.415063  0.595035  1.106202\n",
       "6     BID       7             Naive  0.415749  0.595012  1.108420\n",
       "7     BID      14             Naive  0.414737  0.593709  1.104955\n",
       "8     BID      30             Naive  0.414367  0.594219  1.103302\n",
       "9     BID      90             Naive  0.412766  0.590717  1.094849\n",
       "10    FPT       3  LinearRegression  1.187237  1.680814  1.215549\n",
       "11    FPT       7             Naive  1.192809  1.685614  1.219468\n",
       "12    FPT      14             Naive  1.195771  1.688525  1.221517\n",
       "13    FPT      30             Naive  1.198261  1.692248  1.221464\n",
       "14    FPT      90             Naive  1.205338  1.698462  1.219182\n",
       "15    MBB       3             Naive  0.185861  0.292407  1.104328\n",
       "16    MBB       7             Naive  0.185861  0.292407  1.104328\n",
       "17    MBB      14             Naive  0.186259  0.292874  1.105988\n",
       "18    MBB      30             Naive  0.187202  0.293697  1.111324\n",
       "19    MBB      90             Naive  0.188298  0.295531  1.109522\n",
       "20    VCB       3             Naive  0.491854  0.761055  0.818923\n",
       "21    VCB       7             Naive  0.491854  0.761055  0.818923\n",
       "22    VCB      14             Naive  0.489211  0.758946  0.814442\n",
       "23    VCB      30             Naive  0.489735  0.759966  0.815256\n",
       "24    VCB      90             Naive  0.488859  0.762184  0.813183"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show top models per symbol/window\n",
    "if 'res_df' in globals():\n",
    "    display_cols = [\"symbol\", \"window\", \"model\", \"mae\", \"rmse\", \"mape\"]\n",
    "    best = res_df.sort_values([\"symbol\", \"window\", \"mae\"]).groupby([\"symbol\", \"window\"]).head(1)\n",
    "    display(best[display_cols].reset_index(drop=True))\n",
    "else:\n",
    "    print(\"Run previous cells to compute results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc6bcd",
   "metadata": {},
   "source": [
    "### Optional: install extra libraries\n",
    "If you want to extend beyond baselines, install scikit-learn and gradient boosting libs. In notebooks this may require a restart after installation.\n",
    "\n",
    "- scikit-learn (LinearRegression, RandomForest, SVR, etc.)\n",
    "- xgboost, lightgbm, catboost (gradient boosting)\n",
    "- pytorch or tensorflow/keras (for LSTM/GRU/Transformer)\n",
    "\n",
    "You can run the following in a terminal if desired:\n",
    "\n",
    "- pip install scikit-learn xgboost lightgbm catboost\n",
    "- pip install torch torchvision torchaudio  # or tensorflow\n",
    "\n",
    "Then add models in the loop similarly to LinearRegression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
