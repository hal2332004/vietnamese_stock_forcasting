{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a23db4",
   "metadata": {},
   "source": [
    "# So S√°nh Model: V·ªõi Technical Indicators vs Kh√¥ng C√≥ Indicators\n",
    "\n",
    "Notebook n√†y so s√°nh hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh machine learning khi:\n",
    "- **Scenario 1**: Ch·ªâ s·ª≠ d·ª•ng d·ªØ li·ªáu g·ªëc (OHLCV - Open, High, Low, Close, Volume)\n",
    "- **Scenario 2**: S·ª≠ d·ª•ng d·ªØ li·ªáu g·ªëc + 58 ch·ªâ s·ªë k·ªπ thu·∫≠t\n",
    "\n",
    "**Models**:\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- LSTM (Deep Learning)\n",
    "\n",
    "**M·ª•c ti√™u**: D·ª± ƒëo√°n gi√° ƒë√≥ng c·ª≠a ng√†y ti·∫øp theo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e244e1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdcc965",
   "metadata": {},
   "source": [
    "## 2. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b32521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset WITHOUT indicators (raw OHLCV data)\n",
    "df_raw = pd.read_csv('stock_data_2025_raw.csv')\n",
    "df_raw['time'] = pd.to_datetime(df_raw['time'])\n",
    "df_raw = df_raw.sort_values(['symbol', 'time']).reset_index(drop=True)\n",
    "\n",
    "# Load dataset WITH indicators\n",
    "df_indicators = pd.read_csv('stock_data_2025_with_indicators.csv')\n",
    "df_indicators['time'] = pd.to_datetime(df_indicators['time'])\n",
    "df_indicators = df_indicators.sort_values(['symbol', 'time']).reset_index(drop=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìä Dataset WITHOUT Indicators (Raw):\")\n",
    "print(f\"   Shape: {df_raw.shape}\")\n",
    "print(f\"   Columns: {len(df_raw.columns)} - {df_raw.columns.tolist()}\")\n",
    "print(f\"   Time Range: {df_raw['time'].min()} to {df_raw['time'].max()}\")\n",
    "\n",
    "print(f\"\\nüìà Dataset WITH Indicators:\")\n",
    "print(f\"   Shape: {df_indicators.shape}\")\n",
    "print(f\"   Columns: {len(df_indicators.columns)}\")\n",
    "print(f\"   Time Range: {df_indicators['time'].min()} to {df_indicators['time'].max()}\")\n",
    "print(f\"   Additional Features: {len(df_indicators.columns) - len(df_raw.columns)} technical indicators\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nüìã Sample from Raw Data:\")\n",
    "display(df_raw.head())\n",
    "\n",
    "print(\"\\nüìã Sample from Data with Indicators (first 10 columns):\")\n",
    "display(df_indicators.iloc[:5, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2eccfd",
   "metadata": {},
   "source": [
    "## 3. Prepare Features\n",
    "\n",
    "### 3.1 WITHOUT Indicators (Only OHLCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_data(df):\n",
    "    \"\"\"\n",
    "    Chu·∫©n b·ªã d·ªØ li·ªáu ch·ªâ v·ªõi OHLCV\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create target: next day's close price\n",
    "    df['target'] = df.groupby('symbol')['close'].shift(-1)\n",
    "    \n",
    "    # Remove rows with NaN target\n",
    "    df = df.dropna(subset=['target'])\n",
    "    \n",
    "    # Select features (only OHLCV)\n",
    "    feature_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "    \n",
    "    X = df[feature_cols].values\n",
    "    y = df['target'].values\n",
    "    \n",
    "    return X, y, feature_cols\n",
    "\n",
    "X_raw, y_raw, features_raw = prepare_raw_data(df_raw)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RAW DATA (WITHOUT INDICATORS)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Features: {len(features_raw)}\")\n",
    "print(f\"Feature names: {features_raw}\")\n",
    "print(f\"X shape: {X_raw.shape}\")\n",
    "print(f\"y shape: {y_raw.shape}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856915a",
   "metadata": {},
   "source": [
    "### 3.2 WITH Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_indicator_data(df):\n",
    "    \"\"\"\n",
    "    Chu·∫©n b·ªã d·ªØ li·ªáu v·ªõi t·∫•t c·∫£ indicators\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create target: next day's close price\n",
    "    df['target'] = df.groupby('symbol')['close'].shift(-1)\n",
    "    \n",
    "    # Remove rows with NaN\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Select all features except time, symbol, and target\n",
    "    exclude_cols = ['time', 'symbol', 'target']\n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    X = df[feature_cols].values\n",
    "    y = df['target'].values\n",
    "    \n",
    "    return X, y, feature_cols\n",
    "\n",
    "X_indicators, y_indicators, features_indicators = prepare_indicator_data(df_indicators)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA WITH INDICATORS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Features: {len(features_indicators)}\")\n",
    "print(f\"Feature names (first 20): {features_indicators[:20]}\")\n",
    "print(f\"X shape: {X_indicators.shape}\")\n",
    "print(f\"y shape: {y_indicators.shape}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115c2d27",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_timeseries(X, y, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Time series split: train/test theo th·ªùi gian\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    train_size = int(n * (1 - test_size))\n",
    "    \n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Split RAW data\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split_timeseries(X_raw, y_raw)\n",
    "\n",
    "# Split INDICATOR data\n",
    "X_train_ind, X_test_ind, y_train_ind, y_test_ind = train_test_split_timeseries(X_indicators, y_indicators)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAIN/TEST SPLIT SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä RAW Data (No Indicators):\")\n",
    "print(f\"   Train: {len(X_train_raw)} samples ({len(X_train_raw)/len(X_raw)*100:.1f}%)\")\n",
    "print(f\"   Test:  {len(X_test_raw)} samples ({len(X_test_raw)/len(X_raw)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nüìà Data with Indicators:\")\n",
    "print(f\"   Train: {len(X_train_ind)} samples ({len(X_train_ind)/len(X_indicators)*100:.1f}%)\")\n",
    "print(f\"   Test:  {len(X_test_ind)} samples ({len(X_test_ind)/len(X_indicators)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829ed38",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e573b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    T√≠nh c√°c metrics ƒë√°nh gi√°\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "# Store all results\n",
    "all_results = []\n",
    "\n",
    "print(\"‚úÖ Evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073d190b",
   "metadata": {},
   "source": [
    "## 6. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c94fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LINEAR REGRESSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# WITHOUT Indicators\n",
    "print(\"\\nüîπ Training WITHOUT Indicators...\")\n",
    "lr_raw = LinearRegression()\n",
    "lr_raw.fit(X_train_raw, y_train_raw)\n",
    "y_pred_raw = lr_raw.predict(X_test_raw)\n",
    "metrics_raw = evaluate_model(y_test_raw, y_pred_raw)\n",
    "\n",
    "all_results.append({\n",
    "    'Model': 'Linear Regression',\n",
    "    'Data': 'Without Indicators',\n",
    "    'Features': len(features_raw),\n",
    "    **metrics_raw\n",
    "})\n",
    "\n",
    "print(f\"   MAE: {metrics_raw['MAE']:.4f}\")\n",
    "print(f\"   RMSE: {metrics_raw['RMSE']:.4f}\")\n",
    "print(f\"   R¬≤: {metrics_raw['R2']:.4f}\")\n",
    "print(f\"   MAPE: {metrics_raw['MAPE']:.2f}%\")\n",
    "\n",
    "# WITH Indicators\n",
    "print(\"\\nüî∏ Training WITH Indicators...\")\n",
    "lr_ind = LinearRegression()\n",
    "lr_ind.fit(X_train_ind, y_train_ind)\n",
    "y_pred_ind = lr_ind.predict(X_test_ind)\n",
    "metrics_ind = evaluate_model(y_test_ind, y_pred_ind)\n",
    "\n",
    "all_results.append({\n",
    "    'Model': 'Linear Regression',\n",
    "    'Data': 'With Indicators',\n",
    "    'Features': len(features_indicators),\n",
    "    **metrics_ind\n",
    "})\n",
    "\n",
    "print(f\"   MAE: {metrics_ind['MAE']:.4f}\")\n",
    "print(f\"   RMSE: {metrics_ind['RMSE']:.4f}\")\n",
    "print(f\"   R¬≤: {metrics_ind['R2']:.4f}\")\n",
    "print(f\"   MAPE: {metrics_ind['MAPE']:.2f}%\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\nüìä Improvement with Indicators:\")\n",
    "print(f\"   MAE: {((metrics_raw['MAE'] - metrics_ind['MAE']) / metrics_raw['MAE'] * 100):.2f}%\")\n",
    "print(f\"   RMSE: {((metrics_raw['RMSE'] - metrics_ind['RMSE']) / metrics_raw['RMSE'] * 100):.2f}%\")\n",
    "print(f\"   R¬≤: {((metrics_ind['R2'] - metrics_raw['R2']) / abs(metrics_raw['R2']) * 100):.2f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79cebb",
   "metadata": {},
   "source": [
    "## 7. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae088534",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RANDOM FOREST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# WITHOUT Indicators\n",
    "print(\"\\nüîπ Training WITHOUT Indicators...\")\n",
    "rf_raw = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "rf_raw.fit(X_train_raw, y_train_raw)\n",
    "y_pred_raw = rf_raw.predict(X_test_raw)\n",
    "metrics_raw = evaluate_model(y_test_raw, y_pred_raw)\n",
    "\n",
    "all_results.append({\n",
    "    'Model': 'Random Forest',\n",
    "    'Data': 'Without Indicators',\n",
    "    'Features': len(features_raw),\n",
    "    **metrics_raw\n",
    "})\n",
    "\n",
    "print(f\"   MAE: {metrics_raw['MAE']:.4f}\")\n",
    "print(f\"   RMSE: {metrics_raw['RMSE']:.4f}\")\n",
    "print(f\"   R¬≤: {metrics_raw['R2']:.4f}\")\n",
    "print(f\"   MAPE: {metrics_raw['MAPE']:.2f}%\")\n",
    "\n",
    "# WITH Indicators\n",
    "print(\"\\nüî∏ Training WITH Indicators...\")\n",
    "rf_ind = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "rf_ind.fit(X_train_ind, y_train_ind)\n",
    "y_pred_ind = rf_ind.predict(X_test_ind)\n",
    "metrics_ind = evaluate_model(y_test_ind, y_pred_ind)\n",
    "\n",
    "all_results.append({\n",
    "    'Model': 'Random Forest',\n",
    "    'Data': 'With Indicators',\n",
    "    'Features': len(features_indicators),\n",
    "    **metrics_ind\n",
    "})\n",
    "\n",
    "print(f\"   MAE: {metrics_ind['MAE']:.4f}\")\n",
    "print(f\"   RMSE: {metrics_ind['RMSE']:.4f}\")\n",
    "print(f\"   R¬≤: {metrics_ind['R2']:.4f}\")\n",
    "print(f\"   MAPE: {metrics_ind['MAPE']:.2f}%\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\nüìä Improvement with Indicators:\")\n",
    "print(f\"   MAE: {((metrics_raw['MAE'] - metrics_ind['MAE']) / metrics_raw['MAE'] * 100):.2f}%\")\n",
    "print(f\"   RMSE: {((metrics_raw['RMSE'] - metrics_ind['RMSE']) / metrics_raw['RMSE'] * 100):.2f}%\")\n",
    "print(f\"   R¬≤: {((metrics_ind['R2'] - metrics_raw['R2']) / abs(metrics_raw['R2']) * 100):.2f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e834b5",
   "metadata": {},
   "source": [
    "## 8. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d552aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"XGBOOST\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# WITHOUT Indicators\n",
    "print(\"\\nüîπ Training WITHOUT Indicators...\")\n",
    "xgb_raw = XGBRegressor(n_estimators=100, max_depth=7, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
    "xgb_raw.fit(X_train_raw, y_train_raw)\n",
    "y_pred_raw = xgb_raw.predict(X_test_raw)\n",
    "metrics_raw = evaluate_model(y_test_raw, y_pred_raw)\n",
    "\n",
    "all_results.append({\n",
    "    'Model': 'XGBoost',\n",
    "    'Data': 'Without Indicators',\n",
    "    'Features': len(features_raw),\n",
    "    **metrics_raw\n",
    "})\n",
    "\n",
    "print(f\"   MAE: {metrics_raw['MAE']:.4f}\")\n",
    "print(f\"   RMSE: {metrics_raw['RMSE']:.4f}\")\n",
    "print(f\"   R¬≤: {metrics_raw['R2']:.4f}\")\n",
    "print(f\"   MAPE: {metrics_raw['MAPE']:.2f}%\")\n",
    "\n",
    "# WITH Indicators\n",
    "print(\"\\nüî∏ Training WITH Indicators...\")\n",
    "xgb_ind = XGBRegressor(n_estimators=100, max_depth=7, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
    "xgb_ind.fit(X_train_ind, y_train_ind)\n",
    "y_pred_ind = xgb_ind.predict(X_test_ind)\n",
    "metrics_ind = evaluate_model(y_test_ind, y_pred_ind)\n",
    "\n",
    "all_results.append({\n",
    "    'Model': 'XGBoost',\n",
    "    'Data': 'With Indicators',\n",
    "    'Features': len(features_indicators),\n",
    "    **metrics_ind\n",
    "})\n",
    "\n",
    "print(f\"   MAE: {metrics_ind['MAE']:.4f}\")\n",
    "print(f\"   RMSE: {metrics_ind['RMSE']:.4f}\")\n",
    "print(f\"   R¬≤: {metrics_ind['R2']:.4f}\")\n",
    "print(f\"   MAPE: {metrics_ind['MAPE']:.2f}%\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\nüìä Improvement with Indicators:\")\n",
    "print(f\"   MAE: {((metrics_raw['MAE'] - metrics_ind['MAE']) / metrics_raw['MAE'] * 100):.2f}%\")\n",
    "print(f\"   RMSE: {((metrics_raw['RMSE'] - metrics_ind['RMSE']) / metrics_raw['RMSE'] * 100):.2f}%\")\n",
    "print(f\"   R¬≤: {((metrics_ind['R2'] - metrics_raw['R2']) / abs(metrics_raw['R2']) * 100):.2f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa5d4c",
   "metadata": {},
   "source": [
    "## 9. LSTM (Deep Learning)\n",
    "\n",
    "### 9.1 Data Preparation for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49340105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler_X_raw = MinMaxScaler()\n",
    "scaler_y_raw = MinMaxScaler()\n",
    "scaler_X_ind = MinMaxScaler()\n",
    "scaler_y_ind = MinMaxScaler()\n",
    "\n",
    "# Scale RAW data\n",
    "X_train_raw_scaled = scaler_X_raw.fit_transform(X_train_raw)\n",
    "X_test_raw_scaled = scaler_X_raw.transform(X_test_raw)\n",
    "y_train_raw_scaled = scaler_y_raw.fit_transform(y_train_raw.reshape(-1, 1)).flatten()\n",
    "y_test_raw_scaled = scaler_y_raw.transform(y_test_raw.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Scale INDICATOR data\n",
    "X_train_ind_scaled = scaler_X_ind.fit_transform(X_train_ind)\n",
    "X_test_ind_scaled = scaler_X_ind.transform(X_test_ind)\n",
    "y_train_ind_scaled = scaler_y_ind.fit_transform(y_train_ind.reshape(-1, 1)).flatten()\n",
    "y_test_ind_scaled = scaler_y_ind.transform(y_test_ind.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Create sequences for LSTM\n",
    "def create_sequences(X, y, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "TIME_STEPS = 10\n",
    "\n",
    "# Create sequences for RAW data\n",
    "X_train_raw_seq, y_train_raw_seq = create_sequences(X_train_raw_scaled, y_train_raw_scaled, TIME_STEPS)\n",
    "X_test_raw_seq, y_test_raw_seq = create_sequences(X_test_raw_scaled, y_test_raw_scaled, TIME_STEPS)\n",
    "\n",
    "# Create sequences for INDICATOR data\n",
    "X_train_ind_seq, y_train_ind_seq = create_sequences(X_train_ind_scaled, y_train_ind_scaled, TIME_STEPS)\n",
    "X_test_ind_seq, y_test_ind_seq = create_sequences(X_test_ind_scaled, y_test_ind_scaled, TIME_STEPS)\n",
    "\n",
    "print(\"‚úÖ Data prepared for LSTM\")\n",
    "print(f\"\\nRAW Data Sequences:\")\n",
    "print(f\"   X_train shape: {X_train_raw_seq.shape} (samples, timesteps, features)\")\n",
    "print(f\"   X_test shape: {X_test_raw_seq.shape}\")\n",
    "\n",
    "print(f\"\\nIndicator Data Sequences:\")\n",
    "print(f\"   X_train shape: {X_train_ind_seq.shape}\")\n",
    "print(f\"   X_test shape: {X_test_ind_seq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd8fe5",
   "metadata": {},
   "source": [
    "### 9.2 LSTM WITHOUT Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7cfbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LSTM WITHOUT INDICATORS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Build LSTM model\n",
    "lstm_raw = Sequential([\n",
    "    LSTM(64, activation='relu', return_sequences=True, input_shape=(TIME_STEPS, X_train_raw_seq.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_raw.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"\\nüìã Model Summary:\")\n",
    "lstm_raw.summary()\n",
    "\n",
    "# Train\n",
    "print(\"\\nüîπ Training...\")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history_raw = lstm_raw.fit(\n",
    "    X_train_raw_seq, y_train_raw_seq,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred_raw_scaled = lstm_raw.predict(X_test_raw_seq, verbose=0).flatten()\n",
    "y_pred_raw = scaler_y_raw.inverse_transform(y_pred_raw_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_raw_actual = scaler_y_raw.inverse_transform(y_test_raw_seq.reshape(-1, 1)).flatten()\n",
    "\n",
    "metrics_raw = evaluate_model(y_test_raw_actual, y_pred_raw)\n",
    "\n",
    "all_results.append({\n",
    "    'Model': 'LSTM',\n",
    "    'Data': 'Without Indicators',\n",
    "    'Features': len(features_raw),\n",
    "    **metrics_raw\n",
    "})\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed!\")\n",
    "print(f\"   MAE: {metrics_raw['MAE']:.4f}\")\n",
    "print(f\"   RMSE: {metrics_raw['RMSE']:.4f}\")\n",
    "print(f\"   R¬≤: {metrics_raw['R2']:.4f}\")\n",
    "print(f\"   MAPE: {metrics_raw['MAPE']:.2f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5323a",
   "metadata": {},
   "source": [
    "### 9.3 LSTM WITH Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a95e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LSTM WITH INDICATORS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Build LSTM model\n",
    "lstm_ind = Sequential([\n",
    "    LSTM(64, activation='relu', return_sequences=True, input_shape=(TIME_STEPS, X_train_ind_seq.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_ind.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"\\nüìã Model Summary:\")\n",
    "lstm_ind.summary()\n",
    "\n",
    "# Train\n",
    "print(\"\\nüî∏ Training...\")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history_ind = lstm_ind.fit(\n",
    "    X_train_ind_seq, y_train_ind_seq,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred_ind_scaled = lstm_ind.predict(X_test_ind_seq, verbose=0).flatten()\n",
    "y_pred_ind = scaler_y_ind.inverse_transform(y_pred_ind_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_ind_actual = scaler_y_ind.inverse_transform(y_test_ind_seq.reshape(-1, 1)).flatten()\n",
    "\n",
    "metrics_ind = evaluate_model(y_test_ind_actual, y_pred_ind)\n",
    "\n",
    "all_results.append({\n",
    "    'Model': 'LSTM',\n",
    "    'Data': 'With Indicators',\n",
    "    'Features': len(features_indicators),\n",
    "    **metrics_ind\n",
    "})\n",
    "\n",
    "print(f\"\\n‚úÖ Training completed!\")\n",
    "print(f\"   MAE: {metrics_ind['MAE']:.4f}\")\n",
    "print(f\"   RMSE: {metrics_ind['RMSE']:.4f}\")\n",
    "print(f\"   R¬≤: {metrics_ind['R2']:.4f}\")\n",
    "print(f\"   MAPE: {metrics_ind['MAPE']:.2f}%\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\nüìä Improvement with Indicators:\")\n",
    "print(f\"   MAE: {((metrics_raw['MAE'] - metrics_ind['MAE']) / metrics_raw['MAE'] * 100):.2f}%\")\n",
    "print(f\"   RMSE: {((metrics_raw['RMSE'] - metrics_ind['RMSE']) / metrics_raw['RMSE'] * 100):.2f}%\")\n",
    "print(f\"   R¬≤: {((metrics_ind['R2'] - metrics_raw['R2']) / abs(metrics_raw['R2']) * 100):.2f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651d4cb",
   "metadata": {},
   "source": [
    "## 10. Final Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"FINAL COMPARISON: WITH vs WITHOUT TECHNICAL INDICATORS\")\n",
    "print(\"=\" * 100)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('comparison_results.csv', index=False)\n",
    "print(\"\\n‚úÖ Results saved to 'comparison_results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa0e65c",
   "metadata": {},
   "source": [
    "## 11. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c580729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison charts\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metrics = ['MAE', 'RMSE', 'R2', 'MAPE']\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    models = results_df['Model'].unique()\n",
    "    without_ind = []\n",
    "    with_ind = []\n",
    "    \n",
    "    for model in models:\n",
    "        without_ind.append(results_df[(results_df['Model'] == model) & (results_df['Data'] == 'Without Indicators')][metric].values[0])\n",
    "        with_ind.append(results_df[(results_df['Model'] == model) & (results_df['Data'] == 'With Indicators')][metric].values[0])\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, without_ind, width, label='Without Indicators', color=colors[0], alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, with_ind, width, label='With Indicators', color=colors[1], alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric, fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=15, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.3f}',\n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_chart.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Comparison chart saved as 'comparison_chart.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c567e36",
   "metadata": {},
   "source": [
    "## 12. Summary & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"SUMMARY & KEY INSIGHTS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Calculate average improvement\n",
    "for model in results_df['Model'].unique():\n",
    "    without = results_df[(results_df['Model'] == model) & (results_df['Data'] == 'Without Indicators')]\n",
    "    with_ind = results_df[(results_df['Model'] == model) & (results_df['Data'] == 'With Indicators')]\n",
    "    \n",
    "    print(f\"\\nüîπ {model}:\")\n",
    "    print(f\"   Features: {without['Features'].values[0]} ‚Üí {with_ind['Features'].values[0]}\")\n",
    "    \n",
    "    mae_improve = ((without['MAE'].values[0] - with_ind['MAE'].values[0]) / without['MAE'].values[0] * 100)\n",
    "    rmse_improve = ((without['RMSE'].values[0] - with_ind['RMSE'].values[0]) / without['RMSE'].values[0] * 100)\n",
    "    r2_improve = ((with_ind['R2'].values[0] - without['R2'].values[0]) / abs(without['R2'].values[0]) * 100)\n",
    "    \n",
    "    print(f\"   MAE improvement: {mae_improve:+.2f}%\")\n",
    "    print(f\"   RMSE improvement: {rmse_improve:+.2f}%\")\n",
    "    print(f\"   R¬≤ improvement: {r2_improve:+.2f}%\")\n",
    "    \n",
    "    if mae_improve > 0:\n",
    "        print(f\"   ‚úÖ Technical indicators HELPED improve performance!\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Technical indicators did NOT help (possible overfitting)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"=\" * 100)\n",
    "print(\"\"\"\\n1. Technical indicators can provide additional context for models\n",
    "2. More features doesn't always mean better performance\n",
    "3. Some models (like tree-based) may benefit more from indicators\n",
    "4. Deep learning models might need more data to leverage all indicators\n",
    "5. Consider feature selection to remove redundant indicators\n",
    "\"\"\")\n",
    "print(\"=\" * 100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
