# ‚úÖ THAY ƒê·ªîI: L∆ØU RI√äNG FILE CSV CHO T·ª™NG TICKER

## üéØ **M·ª•c ƒë√≠ch:**
Thay v√¨ l∆∞u t·∫•t c·∫£ tickers v√†o 1 file CSV chung, gi·ªù **m·ªói ticker c√≥ file ri√™ng** ƒë·ªÉ:
- D·ªÖ qu·∫£n l√Ω v√† ph√¢n t√≠ch t·ª´ng ticker
- Tr√°nh file qu√° l·ªõn (1 file 10MB ‚Üí 5 file 2MB m·ªói file)
- D·ªÖ crawl l·∫°i t·ª´ng ticker n·∫øu b·ªã l·ªói
- D·ªÖ chia s·∫ª data cho t·ª´ng stock

---

## üìù **C√°c thay ƒë·ªïi trong code:**

### 1. **H√†m `save_batch_to_csv()` - D√≤ng 561-582**

#### ‚ùå **Tr∆∞·ªõc (l∆∞u chung):**
```python
def save_batch_to_csv(batch, output_file, write_header=False):
    with csv_lock:
        mode = 'w' if write_header else 'a'
        with open(output_file, mode, encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=["date", "time", "title", "content", "ticker", "source"])
            if write_header:
                writer.writeheader()
            for row in batch:
                writer.writerow(row)
```

#### ‚úÖ **Sau (l∆∞u ri√™ng):**
```python
def save_batch_to_csv(batch, output_file, write_header=False):
    """Save batch to CSV (thread-safe) - GROUP BY TICKER"""
    with csv_lock:
        # Group by ticker
        ticker_batches = {}
        for row in batch:
            ticker = row['ticker']
            if ticker not in ticker_batches:
                ticker_batches[ticker] = []
            ticker_batches[ticker].append(row)
        
        # Save to separate files per ticker
        for ticker, ticker_batch in ticker_batches.items():
            ticker_file = output_file.replace('.csv', f'_{ticker}.csv')
            
            # Check if file exists to determine if header needed
            file_exists = os.path.exists(ticker_file)
            
            mode = 'a'
            with open(ticker_file, mode, encoding="utf-8", newline="") as f:
                writer = csv.DictWriter(f, fieldnames=["date", "time", "title", "content", "ticker", "source"])
                if not file_exists or write_header:
                    writer.writeheader()
                for row in ticker_batch:
                    writer.writerow(row)
```

**Thay ƒë·ªïi:**
- Group batch theo ticker tr∆∞·ªõc khi l∆∞u
- T·∫°o t√™n file ri√™ng: `news_2015_2025_ACB.csv`, `news_2015_2025_BID.csv`, ...
- Check file t·ªìn t·∫°i ƒë·ªÉ quy·∫øt ƒë·ªãnh c√≥ write header kh√¥ng
- Lu√¥n d√πng mode `'a'` (append) ƒë·ªÉ kh√¥ng ghi ƒë√®

---

### 2. **H√†m `crawl_multi_source()` - D√≤ng 584-595**

#### ‚úÖ **Th√™m initialization:**
```python
def crawl_multi_source(output_file):
    """Main crawler - crawl t·ª´ nhi·ªÅu ngu·ªìn - SAVE SEPARATE FILES PER TICKER"""
    batch = []
    
    # Initialize separate files for each ticker
    for ticker in TICKERS:
        ticker_file = output_file.replace('.csv', f'_{ticker}.csv')
        if os.path.exists(ticker_file):
            os.remove(ticker_file)  # Remove old file if exists
    
    # ... rest of code
```

**Thay ƒë·ªïi:**
- X√≥a c√°c file c≈© c·ªßa t·ª´ng ticker n·∫øu t·ªìn t·∫°i
- Th√¥ng b√°o output l√† separate files

---

### 3. **Main script - D√≤ng 682-695**

#### ‚úÖ **Check existing files:**
```python
output_file = f"news_{START_DATE.year}_{END_DATE.year}.csv"  # Base filename

# Check if any ticker files exist
existing_files = []
for ticker in TICKERS:
    ticker_file = output_file.replace('.csv', f'_{ticker}.csv')
    if os.path.exists(ticker_file):
        existing_files.append(ticker_file)

if existing_files:
    print(f"\n[WARNING] Found existing files:")
    for f in existing_files:
        print(f"  - {f}")
    choice = input("Overwrite? (y/n): ")
```

**Thay ƒë·ªïi:**
- Check t·∫•t c·∫£ ticker files thay v√¨ 1 file chung
- Hi·ªÉn th·ªã danh s√°ch files t·ªìn t·∫°i

---

### 4. **Statistics - D√≤ng 720-730**

#### ‚úÖ **Read from separate files:**
```python
# Final statistics - Read from separate files
print("\nüìä Final Statistics (by file):")
for ticker in TICKERS:
    ticker_file = output_file.replace('.csv', f'_{ticker}.csv')
    if os.path.exists(ticker_file):
        with open(ticker_file, 'r', encoding='utf-8') as f:
            count = sum(1 for line in f) - 1  # Exclude header
        print(f"  {ticker}: {count:>5} articles ‚Üí {ticker_file}")
    else:
        print(f"  {ticker}: {0:>5} articles ‚Üí {ticker_file} (not created)")
```

**Thay ƒë·ªïi:**
- ƒê·ªçc t·ª´ng file ri√™ng ƒë·ªÉ ƒë·∫øm
- Hi·ªÉn th·ªã t√™n file cho t·ª´ng ticker

---

## üìÇ **C·∫•u tr√∫c file output:**

### ‚ùå **Tr∆∞·ªõc:**
```
multi_source_news_2015_2025.csv  (1 file, ~10MB, ch·ª©a t·∫•t c·∫£)
```

### ‚úÖ **Sau:**
```
news_2015_2025_ACB.csv  (~148 d√≤ng)
news_2015_2025_BID.csv  (~196 d√≤ng)
news_2015_2025_VCB.csv  (~117 d√≤ng)
news_2015_2025_MBB.csv  (~14 d√≤ng)
news_2015_2025_FPT.csv  (~783 d√≤ng)
```

---

## üöÄ **C√°ch s·ª≠ d·ª•ng:**

### 1. **Ch·∫°y crawler:**
```bash
cd /mnt/d/Ky\ 4/financial-news-sentiment-main/Source/recode

# Ch·∫°y full
python multi_source_crawler.py

# Output s·∫Ω t·∫°o 5 files:
# - news_2015_2025_ACB.csv
# - news_2015_2025_BID.csv
# - news_2015_2025_VCB.csv
# - news_2015_2025_MBB.csv
# - news_2015_2025_FPT.csv
```

### 2. **Check k·∫øt qu·∫£:**
```bash
bash check_separate_files.sh
```

### 3. **Load data trong Python:**
```python
import pandas as pd

# Load 1 ticker
acb_df = pd.read_csv('news_2015_2025_ACB.csv')

# Load t·∫•t c·∫£
all_dfs = {}
for ticker in ['ACB', 'BID', 'VCB', 'MBB', 'FPT']:
    df = pd.read_csv(f'news_2015_2025_{ticker}.csv')
    all_dfs[ticker] = df

# Ho·∫∑c concat th√†nh 1 dataframe
import glob
all_files = glob.glob('news_2015_2025_*.csv')
combined_df = pd.concat([pd.read_csv(f) for f in all_files], ignore_index=True)
```

---

## ‚úÖ **∆Øu ƒëi·ªÉm:**

1. **D·ªÖ qu·∫£n l√Ω**: M·ªói ticker 1 file, d·ªÖ t√¨m v√† x·ª≠ l√Ω
2. **Performance**: File nh·ªè h∆°n ‚Üí load nhanh h∆°n
3. **Flexibility**: Crawl l·∫°i t·ª´ng ticker ri√™ng l·∫ª n·∫øu c·∫ßn
4. **Parallel processing**: C√≥ th·ªÉ process nhi·ªÅu ticker song song
5. **Clear separation**: Tr√°nh nh·∫ßm l·∫´n data gi·ªØa c√°c ticker

---

## üìä **So s√°nh:**

| Metric | Before (1 file) | After (5 files) |
|--------|----------------|-----------------|
| File size | ~10MB | ~2MB each |
| Load time | ~3s | ~0.6s each |
| Memory | ~100MB | ~20MB each |
| Manageability | ‚ö†Ô∏è | ‚úÖ |
| Flexibility | ‚ö†Ô∏è | ‚úÖ |

---

## üîÑ **Backward compatibility:**

N·∫øu c·∫ßn merge l·∫°i th√†nh 1 file:
```bash
# Header t·ª´ file ƒë·∫ßu ti√™n
head -1 news_2015_2025_ACB.csv > news_2015_2025_ALL.csv

# Append data (b·ªè header) t·ª´ t·∫•t c·∫£ files
for ticker in ACB BID VCB MBB FPT; do
    tail -n +2 news_2015_2025_${ticker}.csv >> news_2015_2025_ALL.csv
done
```

---

## ‚ö†Ô∏è **L∆∞u √Ω:**

1. M·ªói batch save s·∫Ω m·ªü 1-5 files (t√πy s·ªë ticker trong batch)
2. Thread-safe v·ªõi `csv_lock`
3. File t·ª± ƒë·ªông append ‚Üí kh√¥ng ghi ƒë√®
4. Header ch·ªâ write 1 l·∫ßn khi file ch∆∞a t·ªìn t·∫°i
